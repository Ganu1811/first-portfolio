# linear regression 

# Example 1 (x*2Â )

import numpy as np
from sklearn.linear_model import LinearRegression

# Sample input data
X = np.array([[1], [2], [3], [4], [5]])
y = np.array([2, 4, 6, 8, 10])

# Create a linear regression model
model = LinearRegression()

# Fit the model to the data
model.fit(X, y)

# Predict the output for new data
new_data = np.array([[6], [7]])
predictions = model.predict(new_data)

# Print the predictions
for i, prediction in enumerate(predictions):
    print(f"Prediction {i+1}: {prediction}")




# Example 2 (a+b)

import numpy as np
from sklearn.linear_model import LinearRegression

# Sample input data
X = np.array([[1, 2], [2, 4], [3, 6], [4, 8], [5, 10]])
y = np.array([3, 6, 9, 12, 15])

# Create a linear regression model
model = LinearRegression()

# Fit the model to the data
model.fit(X, y)

# Predict the output for new data
new_data = np.array([[6, 12], [7, 14]])
predictions = model.predict(new_data)

# Print the predictions
for i, prediction in enumerate(predictions):
    print(f"Prediction {i+1}:Â {prediction}")



# Example 3

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
import matplotlib.pyplot as plt
from sklearn.metrics import mean_squared_error


# Read the data from CSV file
df = pd.read_csv('ML\Linear_Regression\house_data.csv')

# Extract the independent variables (house size, number of bedrooms, and distance to city center)
X = df[['House Size (in sq. ft.)', 'Number of Bedrooms',
        'Distance to City Center (in km)']]
# Extract the dependent variable (price)
y = df['Price (in â‚¹1000s)']

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42)

# Create and fit the linear regression model using the training data
regression = LinearRegression()
regression.fit(X_train, y_train)

# Predict the prices for the testing data
y_pred = regression.predict(X_test)

# Plot the actual and predicted prices for the testing data
# plt.scatter(y_test, y_pred)
# plt.xlabel('Actual Price (in â‚¹1000s)')
# plt.ylabel('Predicted Price (in â‚¹1000s)')
# plt.title('Actual vs Predicted Prices (Testing Data)')
# plt.show()

# Plot the scatter plot of actual data
plt.scatter(X_test['House Size (in sq. ft.)'], y_test, label='Actual')
# Plot the linear regression line
plt.plot(X_test['House Size (in sq. ft.)'], y_pred,
         color='red', linewidth=2, label='Predicted')
plt.xlabel('House Size (in sq. ft.)')
plt.ylabel('Price (in â‚¹1000s)')
plt.title('House Price vs. Size with Linear Regression')
plt.legend()
plt.show()

# Calculate the mean squared error
mse = mean_squared_error(y_test, y_pred)
print(f"Mean Squared Error: {mse:.2f}")



# logistic regression 

# Example 1

import numpy as np
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score

# Sample input data
X = np.array([[1], [2], [3], [4], [5]])
y = np.array([0, 0, 0, 1, 1])

# Split the data into training and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
print(X_train)
# Create a logistic regression model
model = LogisticRegression()

# Fit the model to the training data
model.fit(X_train, y_train)

# Make predictions on the test data
y_pred = model.predict(X_test)

# Calculate the accuracy of the model
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)


# Example 2

import numpy as np
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score

# Student marks dataset
# Input features: Study hours and Sleep hours
# Target labels: 1 (Pass) or 0 (Fail)
X = np.array([[5, 7], [2, 8], [3, 5], [8, 3], [10, 6], [6, 9]])
y = np.array([1, 0, 0, 1, 1, 1])

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Create a logistic regression model
model = LogisticRegression()

# Train the model
model.fit(X_train, y_train)

# Predict on the test set
y_pred = model.predict(X_test)

# Calculate accuracy
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)


"""
In this example, we have a dataset with two input features:
 study hours and sleep hours, and the corresponding target labels (pass or fail).

We define the input features X as a 2D array, where each row represents a student,
and each column represents a feature. We also define the target labels y as a 1D array.

We split the data into training and testing sets using train_test_split().
Here, we use 80% of the data for training and 20% for testing, with a random state of 42 for reproducibility.

We create a logistic regression model using LogisticRegression().

We train the model using the fit() method by passing the 
training set features X_train and target labels y_train.

After training, we predict the target labels for the test 
set using the predict() method and pass the test set features X_test.

We calculate the accuracy of the model by comparing the 
predicted labels y_pred with the true labels y_test using the accuracy_score() function.

Finally, we print the accuracy to see how well the logistic 
regression model performs in predicting whether a student will pass or fail
based on their marks (study hours and sleep hours).



# Example 3

import numpy as np
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score

# Set the random seed for reproducibility
np.random.seed(42)

# Total number of students
total_students = 50

# Generate random marks between 0 and 80
marks = np.random.randint(low=0, high=81, size=total_students)

# Set the threshold for passing marks
passing_marks = 38

# Create labels based on marks
labels = np.where(marks >= passing_marks, 1, 0)

# # Create the dataset
# dataset = np.column_stack((marks,labels))
# print(dataset)

reshaped_marks = np.reshape(marks, (-1, 1))

# Split the data into training and test sets
X_train, X_test, y_train, y_test = train_test_split(reshaped_marks, labels, test_size=0.2, random_state=42)
print(y_test)
# Create a logistic regression model
model = LogisticRegression()

# Fit the model to the training data
model.fit(X_train, y_train)

# Make predictions on the test data
y_pred = model.predict(X_test)

# Calculate the accuracy of the model
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)



*** opencv ***


**// to read and display the image

import cv2
import numpy as np
from matplotlib import pyplot as plt
import numpy as np 

# Load an image using 'imread' specifying the path to image
input = cv2.imread('srk.jpg')

# Our file 'input.jpg' is now loaded and stored in python 
# as a varaible we named 'image'

# To display our image variable, we use 'imshow'
# The first parameter will be title shown on image window
# The second parameter is the image varialbe
plt.imshow(cv2.cvtColor(input, cv2.COLOR_BGR2RGB))
plt.title('Hello World')

plt.show()


**// grayscaling of image

# Load our input image
image = cv2.imread('srk.jpg')

# We use cvtColor, to convert to grayscale
gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)

cv2.imshow('Original', image)
cv2.imshow('Grayscale', gray_image)

cv2.waitKey()
cv2.destroyAllWindows()


**// HSV (hue, saturation, value)


#H: 0 - 180, S: 0 - 255, V: 0 - 255
import cv2
import numpy as np
from matplotlib import pyplot as plt
image = cv2.imread('srk.jpg')

hsv_image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)


row, col = 2, 2
fig, axs = plt.subplots(row, col, figsize=(15, 10))
fig.tight_layout()
 
axs[0][0].imshow(cv2.cvtColor(hsv_image, cv2.COLOR_BGR2RGB))
axs[0][0].set_title('HSV image')


axs[0][1].imshow(cv2.cvtColor(hsv_image[:, :, 0], cv2.COLOR_BGR2RGB))
axs[0][1].set_title('Hue channel')

axs[1][0].imshow(cv2.cvtColor(hsv_image[:, :, 1], cv2.COLOR_BGR2RGB))
axs[1][0].set_title('Saturation channel')

axs[1][1].imshow(cv2.cvtColor(hsv_image[:, :, 2], cv2.COLOR_BGR2RGB))
axs[1][1].set_title('Value channel')

plt.show()



**// closer look at color spaces

import cv2
import numpy as np
from matplotlib import pyplot as plt
image = cv2.imread('pizza.jpg')

# BGR Values for the first 0,0 pixel
B, G, R = image[10, 50] 
print (B, G, R)
print (image.shape)

gray_img = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
print (gray_img.shape)
print (gray_img[10, 50]) 

gray_img[0, 0] 

# OpenCV's 'split' function splites the image into each color index
B, G, R = cv2.split(image)

print (B.shape)

row, col = 1, 3
fig, axs = plt.subplots(row, col, figsize=(15, 10))
fig.tight_layout()
 
axs[0].imshow(cv2.cvtColor(R, cv2.COLOR_BGR2RGB))
axs[0].set_title('Red')

axs[1].imshow(cv2.cvtColor(G, cv2.COLOR_BGR2RGB))
axs[1].set_title('Green')

axs[2].imshow(cv2.cvtColor(B, cv2.COLOR_BGR2RGB))
axs[2].set_title('Blue')

plt.show()

row, col = 1, 2
fig, axs = plt.subplots(row, col, figsize=(15, 10))
fig.tight_layout()
 
merged = cv2.merge([B, G, R]) 
axs[0].imshow(cv2.cvtColor(merged, cv2.COLOR_BGR2RGB))
axs[0].set_title('Merged')

merged = cv2.merge([B+100, G, R])
axs[1].imshow(cv2.cvtColor(merged, cv2.COLOR_BGR2RGB))
axs[1].set_title('Merged with Blue Amplified')

plt.show()



**// detail in colors 

import cv2
import numpy as np
from matplotlib import pyplot as plt
image = cv2.imread('srk.jpg')

B, G, R = cv2.split(image)

# Let's create a matrix of zeros 
# with dimensions of the image h x w  
zeros = np.zeros(image.shape[:2], dtype = "uint8")

row, col = 1, 3
fig, axs = plt.subplots(row, col, figsize=(15, 10))
fig.tight_layout()
 
axs[0].imshow(cv2.merge([R, zeros, zeros]))
axs[0].set_title('Red')

axs[1].imshow(cv2.merge([zeros, G, zeros]))
axs[1].set_title('Green')

axs[2].imshow(cv2.merge([zeros, zeros, B]))
axs[2].set_title('Blue')

plt.show()


**// drawing images and shapes using opencv

import cv2
import numpy as np
from matplotlib import pyplot as plt

# Create a black image
image = np.zeros((512,512,3), np.uint8)

# Can we make this in black and white?
image_bw = np.zeros((512,512), np.uint8)

row, col = 1, 2
fig, axs = plt.subplots(row, col, figsize=(15, 10))
fig.tight_layout()
 
axs[0].imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))
axs[0].set_title('Original RGB Colors')

axs[1].imshow(cv2.cvtColor(image_bw, cv2.COLOR_BGR2RGB))
axs[1].set_title('B_W Colors')

plt.show()

# Draw a diagonal blue line of thickness of 5 pixels
image = np.zeros((512,512,3), np.uint8)
cv2.line(image, (0,0), (511,511), (255,127,0), 100)
 
plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))
plt.title('Bule Linear line')

plt.show()

# Draw a Rectangle in
image = np.zeros((512,512,3), np.uint8)

cv2.rectangle(image, (100,100), (300,250), (127,50,127), 30)
plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))

plt.title('Rectangle')

plt.show()

# circle
image = np.zeros((512,512,3), np.uint8)

cv2.circle(image, (350, 350), 100, (15,75,50), 50) 

plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))
plt.title('Circle')
plt.show()

#polygons

image = np.zeros((512,512,3), np.uint8)

# Let's define four points
pts = np.array( [[10,50], [400,50], [90,200], [50,500]], np.int32)

# Let's now reshape our points in form  required by polylines
pts = pts.reshape((-1,1,2))

cv2.polylines(image, [pts], True, (0,0,255), 30)

plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))
plt.title('Polygon')
plt.show()

# add text
image = np.zeros((512,512,3), np.uint8)

cv2.putText(image, 'I love Computer vision', (75,290), cv2.FONT_HERSHEY_COMPLEX, 1, (100,170,0), 3)  
plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))
plt.title('I love Computer vision')
plt.show()


**// shape detection

**// contours

import cv2
import numpy as np
from matplotlib import pyplot as plt

# Let's load a simple image with 3 black squares
image = cv2.imread('contours1.jpg')

plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))
plt.title('Input Image')

plt.show()

# Grayscale
gray = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)

row, col = 1, 2
fig, axs = plt.subplots(row, col, figsize=(15, 10))
fig.tight_layout()

#  we can use canny edges or thresholding
# Find Canny edges
edged = cv2.Canny(gray, 30, 200)
axs[0].imshow(cv2.cvtColor(edged, cv2.COLOR_BGR2RGB))
axs[0].set_title('Canny Edges')

# by thresholding
# ret,thresh = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY)

# Finding Contours
# Use a copy of your image e.g. edged_v2.copy(), since findContours alters the image

contours, H = cv2.findContours(edged.copy(), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)
print(H)
# print(contours)
print("Number of Contours found = " + str(len(contours)))

# Draw all contours
# Use '-1' as the 3rd parameter to draw all
cv2.drawContours(image, contours, -1, (0,0,255), 3)
axs[1].imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))
axs[1].set_title('Contours')

plt.show()


**// shape detection of contours

import cv2
import numpy as np
from matplotlib import pyplot as plt

image = cv2.imread('shapes.jpg')
plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))
plt.title('Identifying Shapes'); plt.show()

gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
ret, thresh = cv2.threshold(gray, 127, 255, 1)

# Find canny edges
# edges = cv2.Canny(gray, 50, 200)
# contours, _ = cv2.findContours(
#     edges.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)

# Extract Contours

contours, _ = cv2.findContours(thresh.copy(), cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)
# print(contours)

original_image = image.copy()

for cnt in contours:
    
    # Get approximate polygons
    # approxPolyDP(cnt, 0.01*cv2.arcLength(cnt,True), True)
    approx = cv2.approxPolyDP(cnt, 0.01*cv2.arcLength(cnt,True), True)
    # print(approx)
    
    M = cv2.moments(cnt)
    cx = int(M['m10'] / M['m00'])
    cy = int(M['m01'] / M['m00'])
    
    if len(approx) == 3:
        shape_name = "Triangle"
        # drawContours(image, contours, contourldx, colour, thickness)
        cv2.drawContours(original_image,[cnt],0,(0,255,0),-1)
        
        # Find contour center to place text at the center

        cv2.putText(original_image, shape_name, (cx-50, cy), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 0), 1)
    
    elif len(approx) == 4:
        x,y,w,h = cv2.boundingRect(cnt)
        
        # Check to see if 4-side polygon is square or rectangle
        # cv2.boundingRect returns the top left and then width and 
        if abs(w-h) <= 3:
            shape_name = "Square"
            # Find contour center to place text at the center
            cv2.drawContours(original_image, [cnt], 0, (0, 125 ,255), -1)
            cv2.putText(original_image, shape_name, (cx-50, cy), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 0), 1)
        else:
            shape_name = "Rectangle"
            
            # Find contour center to place text at the center
            cv2.drawContours(original_image, [cnt], 0, (0, 0, 255), -1)
            cv2.putText(original_image, shape_name, (cx-50, cy), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 0), 1)
            
    elif len(approx) == 10:
        shape_name = "Star"
        cv2.drawContours(original_image, [cnt], 0, (255, 255, 0), -1)

        cv2.putText(original_image, shape_name, (cx-50, cy), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 0), 1)
        
        
        
    elif len(approx) >= 15:
        shape_name = "Circle"
        cv2.drawContours(original_image, [cnt], 0, (0, 255, 255), -1)
        
        cv2.putText(original_image, shape_name, (cx-50, cy), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 0), 1)

    plt.imshow(cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB))
    plt.title('Identifying Shapes')
plt.show()



**// live sketch using webcam

import cv2
import numpy as np

# Our sketch generating function
def sketch(image):
    # Convert image to grayscale
    img_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    
    # Clean up image using Guassian Blur
    img_gray_blur = cv2.GaussianBlur(img_gray, (5,5), 0)
    
    # Extract edges
    canny_edges = cv2.Canny(img_gray_blur, 10, 70)
    
    # Do an invert binarize the image 
    ret, mask = cv2.threshold(canny_edges, 70, 255, cv2.THRESH_BINARY_INV)
    return mask

# Initialize webcam, cap is the object provided by VideoCapture
# It contains a boolean indicating if it was sucessful (ret)
# It also contains the images collected from the webcam (frame)
cap = cv2.VideoCapture(0)

while True:
    ret, frame = cap.read()
    cv2.imshow('Our Live Sketcher', sketch(frame))
    if cv2.waitKey(1) == 13: #13 is the Enter Key
        break
# Release camera and close windows
cap.release()
cv2.destroyAllWindows()      



**// car detection

import cv2
import time
import numpy as np

# Create our body classifier
car_classifier = cv2.CascadeClassifier('cars.xml')

# Initiate video capture for video file
cap = cv2.VideoCapture('cars.avi')

# Loop once video is successfully loaded
while cap.isOpened():
    time.sleep(.05)
    # Read first frame
    _, frame = cap.read()
    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
    
    # Pass frame to our car classifier
    cars = car_classifier.detectMultiScale(gray, 1.4, 2)
    print(cars)
    # Extract bounding boxes for any bodies identified
    for (x,y,w,h) in cars:
        cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 255), 2)
        cv2.imshow('Cars', frame)
        #fourcc = cv2.VideoWriter_fourcc(*'MPEG')
        #out = cv2.VideoWriter('output.avi',fourcc, 20.0, (640,480))

    if cv2.waitKey(1) == 13: #13 is the Enter Key
        break

cap.release()
cv2.destroyAllWindows()



**// face eye detection

import cv2
import numpy as np
from matplotlib import pyplot as plt

# Load our image then convert it to grayscale
image = cv2.imread('t2.jpg')
gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)

# convert from bgr to rgb for matplotlib
plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))
# plt.imshow(cv2.cvtColor(gray, cv2.COLOR_BGR2RGB))
plt.title('Input Image')
plt.show()

# We point OpenCV's CascadeClassifier function to where our 
# classifier (XML file format) is stored
face_classifier = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')

# Our classifier returns the ROI of the detected face as a tuple
# It stores the top left coordinate and the top right coordiantes
faces = face_classifier.detectMultiScale(gray, 1.3, 5)
# print(faces)

# When no faces detected, face_classifier returns and empty tuple
if faces is ():
    print("No faces found")

# We iterate through our faces array and draw a rectangle
# over each face in faces
for (x,y,w,h) in faces:
    cv2.rectangle(image, (x,y), (x+w,y+h), (127,0,255), 2)
    plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))
    plt.title('Face Detection')
plt.show()
    # how to show all in one image

eye_classifier = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_eye.xml')
face_classifier = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')

img = cv2.imread('t2.jpg')
gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

faces = face_classifier.detectMultiScale(gray, 1.3, 5)
# print (faces)
# When no faces detected, face_classifier returns and empty tuple
if faces is ():
    print("No Face Found")

for (x,y,w,h) in faces:
    cv2.rectangle(img,(x,y),(x+w,y+h),(127,0,255),2)
    
    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
    plt.title('img')
    plt.show()
    
    
    # Reducing the region of interest by trimming list
    roi_gray = gray[y:y+h, x:x+w]
    roi_color = img[y:y+h, x:x+w]
    eyes = eye_classifier.detectMultiScale(roi_gray)
    print(eyes)
    for (ex,ey,ew,eh) in eyes:
        cv2.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(255,255,0),2)
        plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
        plt.title('EYES')
        plt.show()


# make with them
cap = cv2.VideoCapture(0)
while 1:
    # reads frames from a camera
    ret, img = cap.read()
    cv2.imshow('img', img)

    # Wait till Esc key pressed to stop
    k = cv2.waitKey(30)
    if k == 27:
        break

# Close the window
cap.release()

# De-allocate any associated memory usage
cv2.destroyAllWindows()

# integrating face and eye detection

# comment niche ke chize n explain one one line
face_classifier = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')
eye_classifier = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_eye.xml')

# capture frames from a camera
cap = cv2.VideoCapture(0)

# loop runs if capturing has been initialized.
while 1:

    # reads frames from a camera
    ret, img = cap.read()

    # convert to gray scale of each frames
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

    # Detects faces of different sizes in the input image
    faces = face_classifier.detectMultiScale(gray, 1.3, 5)
    
    for (x, y, w, h) in faces:
        # To draw a rectangle in a face
        cv2.rectangle(img, (x, y), (x+w, y+h), (255, 255, 0), 2)

        # Reducing the region of interest
        roi_gray = gray[y:y+h, x:x+w]
        roi_color = img[y:y+h, x:x+w]

        # Detects eyes of different sizes in the input image
        eyes = eye_classifier.detectMultiScale(roi_gray, 1.3, 5)

        # To draw a rectangle in eyes
        for (ex, ey, ew, eh) in eyes:
            cv2.rectangle(roi_color, (ex, ey),
                          (ex+ew, ey+eh), (0, 127, 255), 2)

    # Display an image in a window
    cv2.imshow('img', img)

    # Wait till Esc key pressed to stop
    k = cv2.waitKey(30)
    if k == 27:
    # quit with a character key
        break

# Close the window
cap.release()

# De-allocate any associated memory usage
cv2.destroyAllWindows() 